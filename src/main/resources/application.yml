server:
  port: 8803
spring:
  profiles:
    active: "@profiles.active@"
  application:
    name: cloud-exam
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    url: jdbc:mysql://localhost:3306/blog?useUnicode=true&characterEncoding=UTF-8
    username: root
    password: root
    initialSize: 5
    minIdle: 5
    maxActive: 20
    #连接等待超时时间
    maxWait: 60000
    #配置隔多久进行一次检测(检测可以关闭的空闲连接)
    timeBetweenEvictionRunsMillis: 60000
    #配置连接在池中的最小生存时间
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    # 打开PSCache，并且指定每个连接上PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
    filters: stat,wall
    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
    connectionProperties:
      druid:
        stat:
          mergeSql: true
          slowSqlMillis: 5000
    druid:
      stat-view-servlet:
        login-username: admin
        login-password: 888888
#  kafka:
#    bootstrap-servers: 192.168.234.132:9092,192.168.234.132:9093
#    consumer:
#      group-id: test
#      auto-offset-reset: earliest
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
mybatis:
  type-aliases-package: com.lmn.user.domain
  mapper-locations: classpath*:mapper/*.xml
